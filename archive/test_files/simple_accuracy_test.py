#!/usr/bin/env python3
"""
ğŸ¯ SIMPLE ACCURACY TEST

Fast validation test to check if optimized configuration 
can achieve 80%+ accuracy for CIFAR-10
"""

import sys
import os
import time
from datetime import datetime

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def run_simple_test():
    """Run a simple accuracy test with optimized configuration."""
    
    print("ğŸ§ª SIMPLE ACCURACY VALIDATION TEST")
    print("=" * 60)
    print(f"â° Started: {datetime.now().strftime('%H:%M:%S')}")
    print(f"ğŸ¯ Target: 80%+ CIFAR-10 accuracy")
    
    try:
        # Import simple optimized config
        print("\nğŸ“‹ Loading optimized configuration...")
        import simple_optimized_config as config
        print(f"   âœ… Config loaded: {config.DATASET} + {config.MODEL}")
        print(f"   ğŸ“Š Training epochs: {config.GLOBAL_EPOCHS}")
        print(f"   ğŸ“Š Batch size: {config.BATCH_SIZE}")
        print(f"   ğŸ“Š Learning rate: {config.LR}")
        
        # CRITICAL FIX: Override the federated learning config
        print("\nğŸ”§ Overriding federated learning config...")
        import federated_learning.config.config as fl_config
        
        # Copy all config values from our optimized config to fl_config
        for attr in dir(config):
            if not attr.startswith('_'):  # Skip private attributes
                setattr(fl_config, attr, getattr(config, attr))
        
        print(f"   âœ… Config override complete")
        print(f"   ğŸ“Š FL Config now uses: {fl_config.DATASET} + {fl_config.MODEL}")
        
        # Import federated learning components AFTER config override
        print("   Loading federated learning modules...")
        from federated_learning.training.server import Server
        from federated_learning.data.dataset_utils import load_dataset
        from federated_learning.utils.model_utils import set_random_seeds
        
        # Set random seed
        set_random_seeds(config.RANDOM_SEED)
        print(f"   âœ… Random seed set: {config.RANDOM_SEED}")
        
        # Load dataset
        print(f"\nğŸ“‚ Loading {config.DATASET} dataset...")
        start_time = time.time()
        
        root_dataset, test_dataset = load_dataset()
        load_time = time.time() - start_time
        
        print(f"   âœ… Dataset loaded in {load_time:.2f}s")
        print(f"   ğŸ“Š Training samples: {len(root_dataset)}")
        print(f"   ğŸ“Š Test samples: {len(test_dataset)}")
        
        # Create data loader
        import torch
        root_loader = torch.utils.data.DataLoader(
            root_dataset, 
            batch_size=config.BATCH_SIZE, 
            shuffle=True, 
            num_workers=0
        )
        
        # Create server
        print(f"\nğŸ–¥ï¸ Creating server...")
        server = Server()
        server.set_datasets(root_loader, test_dataset)
        print(f"   âœ… Server created with {config.MODEL}")
        
        # Evaluate initial model
        print(f"\nğŸ“ˆ Evaluating initial model...")
        initial_accuracy = server.evaluate_model()
        print(f"   ğŸ“Š Initial accuracy: {initial_accuracy:.4f} ({initial_accuracy:.2%})")
        
        # Pre-train global model (KEY STEP)
        print(f"\nğŸ”§ Pre-training global model for {config.LOCAL_EPOCHS_ROOT} epochs...")
        print(f"   This may take 3-5 minutes for {config.LOCAL_EPOCHS_ROOT} epochs...")
        start_training = time.time()
        
        server._pretrain_global_model()
        
        training_time = time.time() - start_training
        print(f"   âœ… Pre-training completed in {training_time:.2f}s")
        
        # Evaluate after pre-training
        print(f"\nğŸ“Š Evaluating pre-trained model...")
        final_accuracy = server.evaluate_model()
        improvement = final_accuracy - initial_accuracy
        
        print(f"   ğŸ“Š Final accuracy: {final_accuracy:.4f} ({final_accuracy:.2%})")
        print(f"   ğŸ“ˆ Improvement: {improvement:.4f} ({improvement:.2%})")
        
        # Check target achievement
        target_accuracy = 0.80  # 80% target
        
        print(f"\nğŸ¯ TARGET ASSESSMENT:")
        print(f"   Target accuracy: {target_accuracy:.2%}")
        print(f"   Achieved accuracy: {final_accuracy:.2%}")
        
        if final_accuracy >= target_accuracy:
            status = "ğŸ‰ SUCCESS"
            print(f"   {status}: Target achieved!")
        elif final_accuracy >= target_accuracy * 0.9:  # 72%+
            status = "âš ï¸ CLOSE"
            print(f"   {status}: Close to target (90%+ of goal)")
        else:
            status = "âŒ FAILED"
            print(f"   {status}: Below target threshold")
        
        # Summary
        total_time = load_time + training_time
        print(f"\nğŸ“‹ SUMMARY:")
        print(f"   Status: {status}")
        print(f"   Dataset: {config.DATASET}")
        print(f"   Model: {config.MODEL}")
        print(f"   Initial â†’ Final: {initial_accuracy:.2%} â†’ {final_accuracy:.2%}")
        print(f"   Training time: {training_time:.2f}s")
        print(f"   Total time: {total_time:.2f}s")
        
        # Performance analysis
        print(f"\nğŸ” PERFORMANCE ANALYSIS:")
        if final_accuracy >= 0.85:
            print(f"   ğŸŒŸ EXCELLENT: Exceeds research standards")
        elif final_accuracy >= 0.80:
            print(f"   âœ… GOOD: Meets research standards")
        elif final_accuracy >= 0.70:
            print(f"   âš ï¸ ACCEPTABLE: Reasonable for initial test")
        elif final_accuracy >= 0.60:
            print(f"   ğŸ”§ NEEDS_WORK: Requires parameter tuning")
        else:
            print(f"   âŒ POOR: Major configuration issues")
        
        # Recommendations
        print(f"\nğŸ’¡ RECOMMENDATIONS:")
        if final_accuracy >= target_accuracy:
            print(f"   âœ… Configuration is ready for full experiments")
            print(f"   âœ… Proceed with complete attack detection tests")
            print(f"   âœ… Expected paper results: CIFAR-10 accuracy 85-90%")
        elif final_accuracy >= 0.70:  # 70%+
            print(f"   âš ï¸ Good progress, consider minor tweaks:")
            print(f"   âš ï¸ - Increase GLOBAL_EPOCHS to 25-30")
            print(f"   âš ï¸ - Increase LOCAL_EPOCHS_ROOT to 15-20")
        else:
            print(f"   âŒ Major improvements needed:")
            print(f"   âŒ - Increase all epoch counts significantly")
            print(f"   âŒ - Consider larger batch sizes if memory allows")
        
        return {
            'status': status,
            'initial_accuracy': initial_accuracy,
            'final_accuracy': final_accuracy,
            'improvement': improvement,
            'training_time': training_time,
            'total_time': total_time,
            'target_met': final_accuracy >= target_accuracy
        }
        
    except Exception as e:
        print(f"\nâŒ ERROR OCCURRED:")
        print(f"   Error: {str(e)}")
        
        # Try to provide helpful debug info
        import traceback
        print(f"\nğŸ” DEBUG INFO:")
        traceback.print_exc()
        
        return {
            'status': 'âŒ ERROR',
            'error': str(e),
            'target_met': False
        }

if __name__ == "__main__":
    print("ğŸš€ Starting simple accuracy validation...")
    print("ğŸ”§ This test validates optimized configuration for CIFAR-10")
    print("â±ï¸ Expected runtime: 3-5 minutes")
    
    result = run_simple_test()
    
    print(f"\n" + "="*60)
    print(f"âœ… TEST COMPLETED!")
    
    if result.get('target_met', False):
        print(f"ğŸ‰ SUCCESS: Ready for full experiments!")
        print(f"ğŸ“ Next step: Run main.py with optimized config")
    elif result.get('status') == 'âš ï¸ CLOSE':
        print(f"âš ï¸ CLOSE: Minor adjustments recommended")
        print(f"ğŸ“ Next step: Increase epoch counts slightly")
    else:
        print(f"ğŸ”§ NEEDS WORK: Consider parameter adjustments")
        print(f"ğŸ“ Next step: Review and optimize configuration")
    
    print(f"="*60) 